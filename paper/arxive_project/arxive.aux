\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{inception}
\citation{IMAGENET}
\citation{inception}
\citation{inception}
\citation{unn-visual1}
\citation{unn-visual3}
\citation{unn-visual2}
\citation{unn-robustness-noise1}
\citation{unn-universal}
\citation{unn-modar}
\citation{unn-texture}
\citation{unn-texture}
\citation{unn-robustness-geometry}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.~Introduction}{1}{section.1}}
\newlabel{sec:intro}{{1}{1}{\hskip -1em.~Introduction}{section.1}{}}
\@writefile{brf}{\backcite{inception}{{1}{1}{section.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {Semantic Robustness of Deep Networks}. Trained Neural networks can perform poorly for small perturbations in the semantics of the image. (\textit  {top}):We show how for a simple teapot object, perturbing the azimuth view angle of the object can dramatically affect the score of InceptionV3 \cite  {inception} score of the teapot class. (\textit  {bottom}):We show a plot of the softmax confidence scores of different DNNs on the the same teapot object viewed from 360 degrees around the object. For comparison, Lab researchers identified the object from all angles (18 equally spaced samples)\relax }}{1}{figure.caption.1}}
\@writefile{brf}{\backcite{inception}{{1}{1}{figure.caption.1}}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:intro_fig}{{1}{1}{\small \textbf {Semantic Robustness of Deep Networks}. Trained Neural networks can perform poorly for small perturbations in the semantics of the image. (\textit {top}):We show how for a simple teapot object, perturbing the azimuth view angle of the object can dramatically affect the score of InceptionV3 \cite {inception} score of the teapot class. (\textit {bottom}):We show a plot of the softmax confidence scores of different DNNs on the the same teapot object viewed from 360 degrees around the object. For comparison, Lab researchers identified the object from all angles (18 equally spaced samples)\relax }{figure.caption.1}{}}
\@writefile{brf}{\backcite{IMAGENET}{{1}{1}{section.1}}}
\citation{first-attack}
\citation{fast-sign}
\citation{carlini}
\citation{projected-gradient}
\citation{normal-light-attack}
\citation{sada}
\citation{bias}
\citation{strike}
\citation{sada}
\citation{sada}
\citation{unn-visual1}
\citation{unn-visual2}
\citation{unn-visual3}
\citation{unn-robustness-noise1}
\citation{unn-robustness-noise2}
\citation{unn-robustness-noise3}
\citation{unn-robustness-noise4}
\citation{unn-robustness-noise5}
\citation{unn-modar}
\citation{info-lense}
\citation{unn-texture}
\citation{unn-robustness-geometry}
\citation{unn-robustness-measure}
\citation{first-attack}
\citation{fast-sign}
\citation{projected-gradient}
\citation{deepfool}
\citation{carlini}
\citation{reduc-black}
\citation{zeroth-order-attack}
\@writefile{brf}{\backcite{unn-visual1,unn-visual3,unn-visual2}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{unn-robustness-noise1,unn-universal,unn-modar}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{unn-texture,unn-texture,unn-robustness-geometry}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{first-attack,fast-sign,carlini,projected-gradient}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{normal-light-attack,sada}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{bias}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{strike}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{sada}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{sada}{{2}{1}{figure.caption.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.~Related Work}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\hskip -1em.~Understanding Deep Neural Networks}{2}{subsection.2.1}}
\@writefile{brf}{\backcite{unn-visual1,unn-visual2,unn-visual3}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{unn-robustness-noise1,unn-robustness-noise2,unn-robustness-noise3,unn-robustness-noise4,unn-robustness-noise5,unn-modar}{{2}{2.1}{subsection.2.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {Class Global Adversarial Regions}: average scores on $10$ different shapes from the toilet class. We can see these semantic regions are shared among different shapes of that specific class as well as by different DNNs.\relax }}{2}{figure.caption.2}}
\newlabel{fig:global}{{2}{2}{\small \textbf {Class Global Adversarial Regions}: average scores on $10$ different shapes from the toilet class. We can see these semantic regions are shared among different shapes of that specific class as well as by different DNNs.\relax }{figure.caption.2}{}}
\@writefile{brf}{\backcite{info-lense}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{unn-texture}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{unn-robustness-geometry}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{unn-robustness-measure}{{2}{2.1}{subsection.2.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\hskip -1em.~Adversarial Attacks on Deep Neural Networks}{2}{subsection.2.2}}
\@writefile{brf}{\backcite{first-attack}{{2}{2.2}{subsection.2.2}}}
\@writefile{brf}{\backcite{fast-sign,projected-gradient,deepfool,carlini}{{2}{2.2}{subsection.2.2}}}
\@writefile{brf}{\backcite{reduc-black,zeroth-order-attack}{{2}{2.2}{subsection.2.2}}}
\citation{normal-light-attack}
\citation{old-vision1}
\citation{old-vision2}
\citation{vig-nmr}
\citation{paszke2017pytorch}
\citation{sada}
\citation{ioc}
\citation{numerical}
\citation{resnet}
\citation{resnet}
\citation{AlexNet}
\citation{vgg}
\citation{resnet}
\citation{inception}
\citation{sada}
\@writefile{brf}{\backcite{normal-light-attack}{{3}{2.2}{subsection.2.2}}}
\@writefile{brf}{\backcite{old-vision1,old-vision2}{{3}{2.2}{subsection.2.2}}}
\@writefile{brf}{\backcite{vig-nmr}{{3}{2.2}{subsection.2.2}}}
\@writefile{brf}{\backcite{paszke2017pytorch}{{3}{2.2}{subsection.2.2}}}
\@writefile{brf}{\backcite{sada}{{3}{2.2}{subsection.2.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}\hskip -1em.~Optimizing Integral Bounds}{3}{subsection.2.3}}
\@writefile{brf}{\backcite{ioc}{{3}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{numerical}{{3}{2.3}{subsection.2.3}}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.~Methodology}{3}{section.3}}
\newlabel{sec:methodology}{{3}{3}{\hskip -1em.~Methodology}{section.3}{}}
\newlabel{eq:f}{{1}{3}{\hskip -1em.~Methodology}{equation.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.~Region Finding as an Operator}{3}{subsection.3.1}}
\newlabel{sec:operator}{{3.1}{3}{\hskip -1em.~Region Finding as an Operator}{subsection.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {Semantic Robust Region Finding}: finding robust regions of semantic parameters for Rsnet50 \cite  {resnet} in a bathtub object by the three bottom-up formulations (naive , OIR\_W , OIR\_B). (\textit  {left}): 1D case (azimuth angle of camera) with three initial points points. (\textit  {right}): 2D case (azimuth angle and elevation angle of camera) with four initial points. We note that the naive approach usually predicts smaller regions, while the OIR formulations finds more comprehensive regions.\relax }}{4}{figure.caption.3}}
\@writefile{brf}{\backcite{resnet}{{4}{3}{figure.caption.3}}}
\newlabel{fig:operator}{{3}{4}{\small \textbf {Semantic Robust Region Finding}: finding robust regions of semantic parameters for Rsnet50 \cite {resnet} in a bathtub object by the three bottom-up formulations (naive , OIR\_W , OIR\_B). (\textit {left}): 1D case (azimuth angle of camera) with three initial points points. (\textit {right}): 2D case (azimuth angle and elevation angle of camera) with four initial points. We note that the naive approach usually predicts smaller regions, while the OIR formulations finds more comprehensive regions.\relax }{figure.caption.3}{}}
\@writefile{brf}{\backcite{AlexNet}{{4}{\caption@xref {??}{ on input line 147}}{figure.caption.4}}}
\@writefile{brf}{\backcite{vgg}{{4}{\caption@xref {??}{ on input line 147}}{figure.caption.4}}}
\@writefile{brf}{\backcite{resnet}{{4}{\caption@xref {??}{ on input line 147}}{figure.caption.4}}}
\@writefile{brf}{\backcite{inception}{{4}{\caption@xref {??}{ on input line 147}}{figure.caption.4}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {Network Semantic Maps}: plotting the 2D semantic maps (as in Figure~{\ref  {fig:operator} \textit  {right}}) of four different networks on two shapes of a chair class (\textit  {top}) and cup class (\textit  {bottom}).We note that InceptionV3 is very confident about its decision , but the cost is that it creates semantic ``traps" where a sharp fall of performance happens in the middle of a robust region. This behaviour is more apparent for complex shapes (\emph  {e.g}\onedot  the chair in \textit  {top} row)\relax }}{4}{figure.caption.4}}
\newlabel{fig:NMS}{{4}{4}{\small \textbf {Network Semantic Maps}: plotting the 2D semantic maps (as in \figLabel {\ref {fig:operator} \textit {right}}) of four different networks on two shapes of a chair class (\textit {top}) and cup class (\textit {bottom}).We note that InceptionV3 is very confident about its decision , but the cost is that it creates semantic ``traps" where a sharp fall of performance happens in the middle of a robust region. This behaviour is more apparent for complex shapes (\eg the chair in \textit {top} row)\relax }{figure.caption.4}{}}
\@writefile{brf}{\backcite{sada}{{4}{3.1}{subsection.3.1}}}
\newlabel{eq:phi-rob}{{2}{4}{\hskip -1em.~Region Finding as an Operator}{equation.3.2}{}}
\citation{dinckl}
\citation{ioc}
\newlabel{eq:phi-adv}{{3}{5}{\hskip -1em.~Region Finding as an Operator}{equation.3.3}{}}
\newlabel{eq:phi-adv-robust}{{4}{5}{\hskip -1em.~Region Finding as an Operator}{equation.3.4}{}}
\newlabel{eq:n-vol}{{5}{5}{\hskip -1em.~Region Finding as an Operator}{equation.3.5}{}}
\newlabel{eq:n-corners}{{6}{5}{\hskip -1em.~Region Finding as an Operator}{equation.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.~Deriving Update Directions}{5}{subsection.3.2}}
\newlabel{eq:n-function}{{7}{5}{\hskip -1em.~Deriving Update Directions}{equation.3.7}{}}
\newlabel{eq:n-loss-update-naive}{{8}{5}{\hskip -1em.~Deriving Update Directions}{equation.3.8}{}}
\@writefile{brf}{\backcite{dinckl}{{5}{3.2}{equation.3.8}}}
\newlabel{eq:loss-oir}{{9}{5}{\hskip -1em.~Deriving Update Directions}{equation.3.9}{}}
\@writefile{brf}{\backcite{ioc}{{5}{3.2}{equation.3.9}}}
\newlabel{eq:n-corners2}{{10}{5}{\hskip -1em.~Deriving Update Directions}{equation.3.10}{}}
\newlabel{eq:n-function-outer}{{11}{5}{\hskip -1em.~Deriving Update Directions}{equation.3.11}{}}
\newlabel{eq:n-loss-update-outer}{{12}{5}{\hskip -1em.~Deriving Update Directions}{equation.3.12}{}}
\newlabel{eq:n-mask-outer}{{13}{6}{\hskip -1em.~Deriving Update Directions}{equation.3.13}{}}
\newlabel{eq:loss-oir2}{{14}{6}{\hskip -1em.~Deriving Update Directions}{equation.3.14}{}}
\newlabel{eq:update-oir-3}{{15}{6}{\hskip -1em.~Deriving Update Directions}{equation.3.15}{}}
\newlabel{eq:n-gradient}{{16}{6}{\hskip -1em.~Deriving Update Directions}{equation.3.16}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Robust n-dimensional Region Finding for Black-Box DNNs by Outer-Inner Ratios\relax }}{6}{algocf.1}}
\newlabel{alg: black}{{1}{6}{\hskip -1em.~Deriving Update Directions}{algocf.1}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Robust n-dimensional Region Finding for White-Box DNNs by Outer-Inner Ratios\relax }}{6}{algocf.2}}
\newlabel{alg: white}{{2}{6}{\hskip -1em.~Deriving Update Directions}{algocf.2}{}}
\newlabel{eq:n-loss-update-grad}{{17}{6}{\hskip -1em.~Deriving Update Directions}{equation.3.17}{}}
\newlabel{eq:n-mask-grad}{{18}{6}{\hskip -1em.~Deriving Update Directions}{equation.3.18}{}}
\citation{sada}
\citation{semantic-attack}
\citation{shapenet}
\citation{vig-nmr}
\citation{resnet}
\citation{vgg}
\citation{AlexNet}
\citation{inception}
\citation{paszke2017pytorch}
\citation{AlexNet}
\citation{vgg}
\citation{resnet}
\citation{inception}
\citation{paszke2017pytorch}
\citation{paszke2017pytorch}
\citation{inception}
\citation{resnet}
\newlabel{eq:n-update-grad-selection}{{19}{7}{\hskip -1em.~Deriving Update Directions}{equation.3.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.~Experiments}{7}{section.4}}
\newlabel{sec:experiments}{{4}{7}{\hskip -1em.~Experiments}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.~Setup and Data}{7}{subsection.4.1}}
\newlabel{sec:setup}{{4.1}{7}{\hskip -1em.~Setup and Data}{subsection.4.1}{}}
\@writefile{brf}{\backcite{sada,semantic-attack}{{7}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{shapenet}{{7}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{vig-nmr}{{7}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{resnet}{{7}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{vgg}{{7}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{AlexNet}{{7}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{inception}{{7}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{paszke2017pytorch}{{7}{4.1}{subsection.4.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.~Mapping the Networks}{7}{subsection.4.2}}
\newlabel{sec:maps}{{4.2}{7}{\hskip -1em.~Mapping the Networks}{subsection.4.2}{}}
\@writefile{brf}{\backcite{AlexNet}{{7}{\caption@xref {??}{ on input line 19}}{table.caption.7}}}
\@writefile{brf}{\backcite{vgg}{{7}{\caption@xref {??}{ on input line 20}}{table.caption.7}}}
\@writefile{brf}{\backcite{resnet}{{7}{\caption@xref {??}{ on input line 21}}{table.caption.7}}}
\@writefile{brf}{\backcite{inception}{{7}{\caption@xref {??}{ on input line 22}}{table.caption.7}}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {Benchmarking famous DNNs in Semantic Robustness vs error rate}. We develop Semantic Robustness Volume Ratio (SRVR) metric to estimate semantic robustness of famous Networks in Section~{\ref  {sec:application}}. We see that semantic robustness doesn't necessarily depends on the accuracy of the DNN, which motivates studying them as an independent metric from the classification accuracy. Errors are reported from Pytorch official implementation, which we use\cite  {paszke2017pytorch}.\relax }}{7}{table.caption.7}}
\@writefile{brf}{\backcite{paszke2017pytorch}{{7}{1}{table.caption.7}}}
\newlabel{tbl:benchmarking}{{1}{7}{\small \textbf {Benchmarking famous DNNs in Semantic Robustness vs error rate}. We develop Semantic Robustness Volume Ratio (SRVR) metric to estimate semantic robustness of famous Networks in \secLabel {\ref {sec:application}}. We see that semantic robustness doesn't necessarily depends on the accuracy of the DNN, which motivates studying them as an independent metric from the classification accuracy. Errors are reported from Pytorch official implementation, which we use\cite {paszke2017pytorch}.\relax }{table.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\hskip -1em.~Growing Semantic Robust Regions}{7}{subsection.4.3}}
\newlabel{sec:regions}{{4.3}{7}{\hskip -1em.~Growing Semantic Robust Regions}{subsection.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}\hskip -1em.~Applications}{7}{subsection.4.4}}
\newlabel{sec:application}{{4.4}{7}{\hskip -1em.~Applications}{subsection.4.4}{}}
\newlabel{eq:SRVR}{{20}{7}{\hskip -1em.~Applications}{equation.4.20}{}}
\citation{IMAGENET}
\citation{fast-sign}
\citation{IMAGENET}
\citation{IMAGENET}
\citation{IMAGENET}
\citation{IMAGENET}
\citation{unn-modar}
\citation{unn-robustness-noise1}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \topsep 3\p@ plus\p@ minus\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {Semantic Analysis Techniques}: comparing different approaches to analyse the semantic robustness of DNN.\relax }}{8}{table.caption.8}}
\newlabel{tbl:complexity}{{2}{8}{\small \textbf {Semantic Analysis Techniques}: comparing different approaches to analyse the semantic robustness of DNN.\relax }{table.caption.8}{}}
\@writefile{brf}{\backcite{inception}{{8}{4.4}{equation.4.20}}}
\@writefile{brf}{\backcite{resnet}{{8}{4.4}{equation.4.20}}}
\newlabel{sec:data-bias}{{4.4}{8}{\hskip -1em.~Applications}{equation.4.20}{}}
\@writefile{brf}{\backcite{IMAGENET}{{8}{4.4}{equation.4.20}}}
\@writefile{brf}{\backcite{fast-sign}{{8}{4.4}{equation.4.20}}}
\@writefile{brf}{\backcite{IMAGENET}{{8}{4.4}{equation.4.20}}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {Semantic Bias in ImageNet}. By taking the average semantic maps over 10 shapes of cup class and over different networks, we get a visualization of the bias of the data. Those angles of low score are probably not well-represented in ImageNet\cite  {IMAGENET}.\relax }}{8}{figure.caption.9}}
\@writefile{brf}{\backcite{IMAGENET}{{8}{5}{figure.caption.9}}}
\newlabel{fig:2d-semantic}{{5}{8}{\small \textbf {Semantic Bias in ImageNet}. By taking the average semantic maps over 10 shapes of cup class and over different networks, we get a visualization of the bias of the data. Those angles of low score are probably not well-represented in ImageNet\cite {IMAGENET}.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.~Analysis}{8}{section.5}}
\newlabel{sec:analysis}{{5}{8}{\hskip -1em.~Analysis}{section.5}{}}
\@writefile{brf}{\backcite{IMAGENET}{{8}{5}{section.5}}}
\@writefile{brf}{\backcite{unn-modar,unn-robustness-noise1}{{8}{5}{section.5}}}
\citation{think}
\bibstyle{ieee}
\bibdata{egbib}
\bibcite{strike}{1}
\bibcite{unn-robustness-noise2}{2}
\bibcite{unn-modar}{3}
\bibcite{unn-robustness-noise3}{4}
\bibcite{Boyd}{5}
\bibcite{carlini}{6}
\bibcite{shapenet}{7}
\bibcite{zeroth-order-attack}{8}
\bibcite{unn-visual1}{9}
\bibcite{unn-robustness-measure}{10}
\bibcite{unn-robustness-noise1}{11}
\bibcite{unn-robustness-geometry}{12}
\bibcite{unn-texture}{13}
\bibcite{fast-sign}{14}
\bibcite{unn-robustness-noise4}{15}
\bibcite{old-vision1}{16}
\bibcite{old-vision2}{17}
\@writefile{brf}{\backcite{think}{{9}{5}{section.5}}}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.~Conclusion}{9}{section.6}}
\bibcite{sada}{18}
\bibcite{resnet}{19}
\bibcite{semantic-attack}{20}
\bibcite{think}{21}
\bibcite{vig-nmr}{22}
\bibcite{AlexNet}{23}
\bibcite{projected-gradient}{24}
\bibcite{unn-visual2}{25}
\bibcite{unn-universal}{26}
\bibcite{deepfool}{27}
\bibcite{reduc-black}{28}
\bibcite{paszke2017pytorch}{29}
\bibcite{dinckl}{30}
\bibcite{IMAGENET}{31}
\bibcite{info-lense}{32}
\bibcite{ioc}{33}
\bibcite{vgg}{34}
\bibcite{numerical}{35}
\bibcite{inception}{36}
\bibcite{unn-robustness-noise5}{37}
\bibcite{first-attack}{38}
\bibcite{bias}{39}
\bibcite{unn-visual3}{40}
\bibcite{normal-light-attack}{41}
\citation{IMAGENET}
\citation{IMAGENET}
\citation{IMAGENET}
\citation{IMAGENET}
\citation{IMAGENET}
\@writefile{toc}{\contentsline {section}{\numberline {A}\hskip -1em.~Analyzing Deep Neural Networks}{11}{appendix.A}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}\hskip -1em.~Networks Semantic Maps (1D)}{11}{subsection.A.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}\hskip -1em.~Networks Semantic Maps (2D)}{11}{subsection.A.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}\hskip -1em.~Convergence of the Region Finding Algorithms}{11}{subsection.A.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4}\hskip -1em.~Examples of Found Regions ( with Example Renderings)}{11}{subsection.A.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.5}\hskip -1em.~Analyzing Semantic Data Bias in ImageNet}{11}{subsection.A.5}}
\@writefile{brf}{\backcite{IMAGENET}{{11}{A.5}{subsection.A.5}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {1D Network Semantic Maps NMS-I}: visualizing 1D Semantic Robustness profile for different networks averaged over 10 different shapes. Observe that different DNNs profiles differ depending on the training , accuracy , and network architectures that all result in a unique ''signatures" for the DNN on that class. The correlation between the DNN profiles is due to the common data bias in ImageNet.\relax }}{12}{figure.caption.11}}
\newlabel{fig:nsm1d-1}{{6}{12}{\small \textbf {1D Network Semantic Maps NMS-I}: visualizing 1D Semantic Robustness profile for different networks averaged over 10 different shapes. Observe that different DNNs profiles differ depending on the training , accuracy , and network architectures that all result in a unique ''signatures" for the DNN on that class. The correlation between the DNN profiles is due to the common data bias in ImageNet.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {1D Network Semantic Maps NMS-II}: visualizing 1D Semantic Robustness profile for different networks averaged over 10 different shapes. Observe that different DNNs profiles differ depending on the training , accuracy , and network architectures that all result in a unique ''signatures" for the DNN on that class. The correlation between the DNN profiles is due to the common data bias in ImageNet.\relax }}{13}{figure.caption.12}}
\newlabel{fig:nsm1d-2}{{7}{13}{\small \textbf {1D Network Semantic Maps NMS-II}: visualizing 1D Semantic Robustness profile for different networks averaged over 10 different shapes. Observe that different DNNs profiles differ depending on the training , accuracy , and network architectures that all result in a unique ''signatures" for the DNN on that class. The correlation between the DNN profiles is due to the common data bias in ImageNet.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {2D Network Semantic Maps NMS-I}. Visualizing 2D Semantic Robustness profile for different networks averaged over 10 different shapes. Every row is different class. observe that different DNNs profiles differ depending on the training , accuracy , and network architectures that all result in a unique ''signatures" for the DNN on that class.\relax }}{14}{figure.caption.13}}
\newlabel{fig:nsm2d-1}{{8}{14}{\small \textbf {2D Network Semantic Maps NMS-I}. Visualizing 2D Semantic Robustness profile for different networks averaged over 10 different shapes. Every row is different class. observe that different DNNs profiles differ depending on the training , accuracy , and network architectures that all result in a unique ''signatures" for the DNN on that class.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {2D Network Semantic Maps NMS-II}: visualizing 2D Semantic Robustness profile for different networks averaged over 10 different shapes. Every row is different class. observe that different DNNs profiles differ depending on the training , accuracy , and network architectures that all result in a unique ''signatures" for the DNN on that class.\relax }}{15}{figure.caption.14}}
\newlabel{fig:nsm2d-2}{{9}{15}{\small \textbf {2D Network Semantic Maps NMS-II}: visualizing 2D Semantic Robustness profile for different networks averaged over 10 different shapes. Every row is different class. observe that different DNNs profiles differ depending on the training , accuracy , and network architectures that all result in a unique ''signatures" for the DNN on that class.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {Robust Region Detection with different initializations}: visualizing the Robust Regions Bounds found by the three algorithms for four initial points. We can see that the naive produce different bounds of the same region for different initializations while OIR detect the same region regardless of initialization.\relax }}{16}{figure.caption.15}}
\newlabel{fig:converge}{{10}{16}{\small \textbf {Robust Region Detection with different initializations}: visualizing the Robust Regions Bounds found by the three algorithms for four initial points. We can see that the naive produce different bounds of the same region for different initializations while OIR detect the same region regardless of initialization.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {Robust Region Bounds Growing I}: visualizing the bounds growing Using different algorithms from two different initializations (120 and 140) in Figure~{\ref  {fig:converge}}. We can see that OIR formulations converge to the same bounds of the robust region regardless of the initialization, which indicates effectiveness in detecting these regions, unlike the naive approach which can stop in a local optimum. \relax }}{17}{figure.caption.16}}
\newlabel{fig:conv1}{{11}{17}{\small \textbf {Robust Region Bounds Growing I}: visualizing the bounds growing Using different algorithms from two different initializations (120 and 140) in \figLabel {\ref {fig:converge}}. We can see that OIR formulations converge to the same bounds of the robust region regardless of the initialization, which indicates effectiveness in detecting these regions, unlike the naive approach which can stop in a local optimum. \relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {Robust Region Bounds Growing I}: visualizing the bounds growing Using different algorithms from two different initializations (290, 310) in Figure~{\ref  {fig:converge}}. We can see that OIR formulations converge to the same bounds of the robust region regardless of the initialization, which indicates effectiveness in detecting these regions, unlike the naive approach which can stop in a local optimum. \relax }}{18}{figure.caption.17}}
\newlabel{fig:conv2}{{12}{18}{\small \textbf {Robust Region Bounds Growing I}: visualizing the bounds growing Using different algorithms from two different initializations (290, 310) in \figLabel {\ref {fig:converge}}. We can see that OIR formulations converge to the same bounds of the robust region regardless of the initialization, which indicates effectiveness in detecting these regions, unlike the naive approach which can stop in a local optimum. \relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {Qualitative Examples of Robust Regions I}: visualizing different runs of the algorithm to find robust regions along with different renderings from inside these regions for those specific shapes used in the experiments. \relax }}{19}{figure.caption.18}}
\newlabel{fig:ex1}{{13}{19}{\small \textbf {Qualitative Examples of Robust Regions I}: visualizing different runs of the algorithm to find robust regions along with different renderings from inside these regions for those specific shapes used in the experiments. \relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {Qualitative Examples of Robust Regions II}: visualizing different runs of the algorithm to find robust regions along with different renderings from inside these regions for those specific shapes used in the experiments.\relax }}{20}{figure.caption.19}}
\newlabel{fig:ex2}{{14}{20}{\small \textbf {Qualitative Examples of Robust Regions II}: visualizing different runs of the algorithm to find robust regions along with different renderings from inside these regions for those specific shapes used in the experiments.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {Data Semantic Maps DSM-I}: visualizing Semantic Data Bias in the common training dataset (\emph  {i.e}\onedot  ImageNet \cite  {IMAGENET}) by averaging the Networks Semantic Maps (NSM) of different networks and on different shapes, Different classes have different semantic bias in ImageNet as clearly shown in the maps above. The symmetry in the maps are attributed to the 3D symmetry of the objects. \relax }}{21}{figure.caption.20}}
\@writefile{brf}{\backcite{IMAGENET}{{21}{15}{figure.caption.20}}}
\newlabel{fig:dsm1}{{15}{21}{\small \textbf {Data Semantic Maps DSM-I}: visualizing Semantic Data Bias in the common training dataset (\ie ImageNet \cite {IMAGENET}) by averaging the Networks Semantic Maps (NSM) of different networks and on different shapes, Different classes have different semantic bias in ImageNet as clearly shown in the maps above. The symmetry in the maps are attributed to the 3D symmetry of the objects. \relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip \textbf  {Data Semantic Maps DSM-II}: visualizing Semantic Data Bias in the common training dataset (\emph  {i.e}\onedot  ImageNet \cite  {IMAGENET}) By averaging the Networks Semantic Maps (NSM) of different networks and on different shapes, Different classes have different semantic bias in ImageNet as clearly shown in the maps above. The symmetry in the maps are attributed to the 3D symmetry of the objects.\relax }}{22}{figure.caption.21}}
\@writefile{brf}{\backcite{IMAGENET}{{22}{16}{figure.caption.21}}}
\newlabel{fig:dsm2}{{16}{22}{\small \textbf {Data Semantic Maps DSM-II}: visualizing Semantic Data Bias in the common training dataset (\ie ImageNet \cite {IMAGENET}) By averaging the Networks Semantic Maps (NSM) of different networks and on different shapes, Different classes have different semantic bias in ImageNet as clearly shown in the maps above. The symmetry in the maps are attributed to the 3D symmetry of the objects.\relax }{figure.caption.21}{}}
\citation{ioc}
\citation{Boyd}
\@writefile{toc}{\contentsline {section}{\numberline {B}\hskip -1em.~Detailed Derivations of the Update Directions of the Bounds}{23}{appendix.B}}
\newlabel{eq:f-sup}{{21}{23}{\hskip -1em.~Detailed Derivations of the Update Directions of the Bounds}{equation.B.21}{}}
\newlabel{eq:phi-rob-sup}{{22}{23}{\hskip -1em.~Detailed Derivations of the Update Directions of the Bounds}{equation.B.22}{}}
\newlabel{eq:phi-adv-sup}{{23}{23}{\hskip -1em.~Detailed Derivations of the Update Directions of the Bounds}{equation.B.23}{}}
\newlabel{eq:phi-adv-robust-sup}{{24}{23}{\hskip -1em.~Detailed Derivations of the Update Directions of the Bounds}{equation.B.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}\hskip -1em.~Divergence of the Bounds}{23}{subsection.B.1}}
\@writefile{brf}{\backcite{ioc}{{23}{B.1}{subsection.B.1}}}
\newlabel{thm:integral}{{B.1}{23}{}{theorem.B.1}{}}
\@writefile{brf}{\backcite{Boyd}{{23}{B.1}{theorem.B.1}}}
\newlabel{thm:unbounded}{{B.2}{23}{}{theorem.B.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}\hskip -1em.~Naive Approach}{23}{subsection.B.2}}
\newlabel{eq:loss-naive-sup}{{25}{23}{\hskip -1em.~Naive Approach}{equation.B.25}{}}
\newlabel{eq:update-naive-1-sup}{{26}{23}{\hskip -1em.~Naive Approach}{equation.B.26}{}}
\citation{dinckl}
\newlabel{eq:naive-integration2}{{27}{24}{\hskip -1em.~Naive Approach}{equation.B.27}{}}
\newlabel{eq:naive-integration3}{{28}{24}{\hskip -1em.~Naive Approach}{equation.B.28}{}}
\newlabel{eq:update-naive-2-sup}{{29}{24}{\hskip -1em.~Naive Approach}{equation.B.29}{}}
\newlabel{eq:update-naive-3-sup}{{30}{24}{\hskip -1em.~Naive Approach}{equation.B.30}{}}
\newlabel{eq:n-vol-sup}{{31}{24}{\hskip -1em.~Naive Approach}{equation.B.31}{}}
\newlabel{eq:n-corners-sup}{{32}{24}{\hskip -1em.~Naive Approach}{equation.B.32}{}}
\newlabel{eq:n-mask-sup}{{33}{24}{\hskip -1em.~Naive Approach}{equation.B.33}{}}
\newlabel{eq:n-function-sup}{{34}{24}{\hskip -1em.~Naive Approach}{equation.B.34}{}}
\newlabel{eq:n-loss-update-naive-sup}{{35}{24}{\hskip -1em.~Naive Approach}{equation.B.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{24}{subsection.B.3}}
\newlabel{eq:fixed-assumption}{{36}{24}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.36}{}}
\@writefile{brf}{\backcite{dinckl}{{24}{B.3}{equation.B.36}}}
\newlabel{eq:loss-oir-sup}{{37}{24}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.37}{}}
\newlabel{eq:oir-b-loss}{{38}{25}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.38}{}}
\newlabel{eq:update-ioc-1}{{39}{25}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.39}{}}
\newlabel{eq:fixed-assumption-2}{{40}{25}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.40}{}}
\newlabel{eq:outer-integration2}{{41}{25}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.41}{}}
\newlabel{eq:outer-integration3}{{42}{25}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.42}{}}
\newlabel{eq:update-outer-2}{{43}{25}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.43}{}}
\newlabel{eq:update-outer-2-1}{{44}{25}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.44}{}}
\newlabel{eq:update-outer-2-2}{{45}{25}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.45}{}}
\newlabel{eq:update-outer-2-3}{{46}{25}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.46}{}}
\newlabel{eq:update-outer-2-4}{{47}{25}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.47}{}}
\newlabel{eq:n-corners2-sup}{{48}{26}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.48}{}}
\newlabel{eq:n-function-outer-sup}{{49}{26}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.49}{}}
\newlabel{eq:n-loss-update-outer-sup}{{50}{26}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.50}{}}
\newlabel{eq:n-mask-outer-sup}{{51}{26}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.51}{}}
\newlabel{eq:loss-oir2-sup}{{52}{26}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.52}{}}
\newlabel{eq:update-oir-1}{{53}{26}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.53}{}}
\newlabel{eq:update-oir-2}{{54}{26}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.54}{}}
\newlabel{eq:update-oir-3-sup}{{55}{26}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.55}{}}
\newlabel{eq:update-oir-4}{{56}{26}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.56}{}}
\newlabel{eq:fixed-assumption-2-w}{{57}{26}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.57}{}}
\newlabel{eq:outer-integration2-w}{{58}{27}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.58}{}}
\newlabel{eq:outer-integration3-w}{{59}{27}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.59}{}}
\newlabel{eq:update-outer-2-w}{{60}{27}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.60}{}}
\newlabel{eq:update-outer-2-w-2}{{61}{27}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.61}{}}
\newlabel{eq:update-outer-2-w-3}{{62}{27}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.62}{}}
\newlabel{eq:update-outer-2-1-w}{{63}{27}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.63}{}}
\newlabel{eq:update-outer-2-2-w}{{64}{27}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.64}{}}
\newlabel{eq:update-outer-2-3-w}{{65}{27}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.65}{}}
\newlabel{eq:update-outer-2-4-w}{{66}{27}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.66}{}}
\citation{numerical}
\newlabel{eq:n-loss-update-grad-sup}{{67}{28}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.67}{}}
\newlabel{eq:n-mask-grad-sup}{{68}{28}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.68}{}}
\newlabel{eq:n-update-grad-selection-sup}{{69}{28}{\hskip -1em.~Outer-Inner Ratio Loss (OIR)}{equation.B.69}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4}\hskip -1em.~Trapezoidal Approximation Formulation}{28}{subsection.B.4}}
\@writefile{brf}{\backcite{numerical}{{28}{B.4}{subsection.B.4}}}
\newlabel{eq:trapezoidal-integration}{{70}{28}{\hskip -1em.~Trapezoidal Approximation Formulation}{equation.B.70}{}}
\newlabel{eq:loss-trap-1}{{71}{28}{\hskip -1em.~Trapezoidal Approximation Formulation}{equation.B.71}{}}
\newlabel{eq:update-trap-1}{{72}{28}{\hskip -1em.~Trapezoidal Approximation Formulation}{equation.B.72}{}}
\newlabel{eq:trapezoidal-integration2}{{73}{28}{\hskip -1em.~Trapezoidal Approximation Formulation}{equation.B.73}{}}
\newlabel{eq:update-trap-2-1}{{74}{28}{\hskip -1em.~Trapezoidal Approximation Formulation}{equation.B.74}{}}
\newlabel{eq:update-trap-2-2}{{75}{28}{\hskip -1em.~Trapezoidal Approximation Formulation}{equation.B.75}{}}
\newlabel{eq:update-trap-2-3}{{76}{28}{\hskip -1em.~Trapezoidal Approximation Formulation}{equation.B.76}{}}
\newlabel{eq:update-trap-2-4}{{77}{28}{\hskip -1em.~Trapezoidal Approximation Formulation}{equation.B.77}{}}
\newlabel{eq:n-loss-trap}{{78}{29}{\hskip -1em.~Trapezoidal Approximation Formulation}{equation.B.78}{}}
\newlabel{eq:n-gradient-sup}{{79}{29}{\hskip -1em.~Trapezoidal Approximation Formulation}{equation.B.79}{}}
\newlabel{eq:n-update-trap}{{80}{29}{\hskip -1em.~Trapezoidal Approximation Formulation}{equation.B.80}{}}
\citation{sada}
\citation{strike}
\citation{shapenet}
\@writefile{toc}{\contentsline {section}{\numberline {C}\hskip -1em.~Analysis}{30}{appendix.C}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}\hskip -1em.~Detected Robust Regions}{30}{subsection.C.1}}
\@writefile{brf}{\backcite{sada,strike}{{30}{C.1}{subsection.C.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}\hskip -1em.~hyper-parameters}{30}{subsection.C.2}}
\newlabel{eq:gamma}{{81}{30}{\hskip -1em.~hyper-parameters}{equation.C.81}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}\hskip -1em.~Detest}{30}{subsection.C.3}}
\@writefile{brf}{\backcite{shapenet}{{30}{C.3}{subsection.C.3}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.4}\hskip -1em.~Possible Future Directions}{30}{subsection.C.4}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces \textbf  {Semantic Analysis Techniques}: comparing different approaches to analyse the semantic robustness of DNN.\relax }}{31}{table.caption.22}}
\newlabel{tbl:complexity-sup}{{3}{31}{\textbf {Semantic Analysis Techniques}: comparing different approaches to analyse the semantic robustness of DNN.\relax }{table.caption.22}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Robust n-dimensional Region Finding for Black-Box DNNs by Outer-Inner Ratios\relax }}{31}{algocf.3}}
\newlabel{alg: black-sup}{{3}{31}{\hskip -1em.~Possible Future Directions}{algocf.3}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Robust n-dimensional Region Finding for White-Box DNNs by Outer-Inner Ratios\relax }}{31}{algocf.4}}
\newlabel{alg: white-sup}{{4}{31}{\hskip -1em.~Possible Future Directions}{algocf.4}{}}
